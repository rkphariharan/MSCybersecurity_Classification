# Import libraries
import pandas as pd
from sklearn.model_selection import StratifiedKFold, cross_val_score, RandomizedSearchCV
from sklearn.metrics import f1_score, make_scorer, classification_report
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

# Paths
train_path = r"C:\Users\rkpha\Desktop\MS Cybersecurity\final\train_split.csv"
val_path = r"C:\Users\rkpha\Desktop\MS Cybersecurity\final\val_split.csv"

# Load data
train_df = pd.read_csv(train_path)
val_df = pd.read_csv(val_path)

X_train = train_df.drop(columns=['IncidentGrade'])
y_train = train_df['IncidentGrade']
X_val = val_df.drop(columns=['IncidentGrade'])
y_val = val_df['IncidentGrade']

# Setup
f1_macro = make_scorer(f1_score, average='macro')
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Store model performances
final_model_performance = {}

# ============================
# 1. Decision Tree Classifier
# ============================
print("\nüöÄ Training Decision Tree Classifier (Baseline Model)...")

dtree = DecisionTreeClassifier(random_state=42, max_depth=10)  # Light tuning
dtree.fit(X_train, y_train)
y_pred_dtree = dtree.predict(X_val)

print("\nüìã Decision Tree Evaluation:")
print(classification_report(y_val, y_pred_dtree, digits=4))
final_model_performance['Decision Tree'] = f1_score(y_val, y_pred_dtree, average='macro')

# ============================
# 2. Random Forest Classifier
# ============================
print("\nüöÄ Running Random Forest Classifier with Light Tuning...")

rf_params = {
    'n_estimators': [100, 200, 300],
    'max_depth': [8, 10, 12],
    'min_samples_split': [2, 5, 10]
}

rf_model = RandomForestClassifier(random_state=42)
rf_search = RandomizedSearchCV(
    estimator=rf_model,
    param_distributions=rf_params,
    n_iter=10,
    scoring=f1_macro,
    cv=skf,
    verbose=2,
    random_state=42,
    n_jobs=-1
)

rf_search.fit(X_train, y_train)
best_rf = rf_search.best_estimator_

y_pred_rf = best_rf.predict(X_val)

print("\nüìã Random Forest Evaluation:")
print(classification_report(y_val, y_pred_rf, digits=4))
final_model_performance['Random Forest'] = f1_score(y_val, y_pred_rf, average='macro')

# ============================
# 3. XGBoost Classifier
# ============================
print("\nüöÄ Running XGBoost Classifier with Light Tuning...")

xgb_params = {
    'n_estimators': [100, 200, 300],
    'max_depth': [4, 6, 8],
    'learning_rate': [0.05, 0.1, 0.2],
    'subsample': [0.7, 0.8, 1.0],
    'colsample_bytree': [0.7, 0.8, 1.0]
}

xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)
xgb_search = RandomizedSearchCV(
    estimator=xgb_model,
    param_distributions=xgb_params,
    n_iter=10,
    scoring=f1_macro,
    cv=skf,
    verbose=2,
    random_state=42,
    n_jobs=1
)

xgb_search.fit(X_train, y_train)
best_xgb = xgb_search.best_estimator_

y_pred_xgb = best_xgb.predict(X_val)

print("\nüìã XGBoost Evaluation:")
print(classification_report(y_val, y_pred_xgb, digits=4))
final_model_performance['XGBoost'] = f1_score(y_val, y_pred_xgb, average='macro')

# ============================
# 4. Final Comparison
# ============================
print("\nüèÅ Final Model Performance (Macro-F1 Scores):")
for model, score in final_model_performance.items():
    print(f"{model}: {score:.4f}")
